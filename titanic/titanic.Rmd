---
title: "titanic"
output: html_document
---

Here we will compare the performance of different machine learning algorithms on titanic dataset

Sections to cover:

 * one-hot encoding
 * model comparison (RF, SVM, NB, LDA, KNN)
 * other models (neural network, xgboost)
 * feature selection
 * hyperparameter tuning
 * autoML
 

```{r setup, include=FALSE}
library(readr) # CSV file I/O, e.g. the read_csv function
library(reshape2)
library(tidyr)
library(dplyr)
#ML
#library(rattle)
library(caret) 
library(caretEnsemble)
library(xgboost)
library(neuralnet)
library(h2o)
h2o.init()
library(ggplot2) # Data visualization
```

```{r message=F, error=F}
train <- read_csv("train.csv")
test <- read_csv("test.csv")

train <- train %>% 
  select(-c(PassengerId,Ticket,Cabin, Name)) %>% 
  mutate(Survived = factor(Survived), Pclass=factor(Pclass))

test <- test %>% 
  dplyr::select(-c(PassengerId,Ticket,Cabin, Name)) %>% 
  mutate(Pclass=factor(Pclass))
```

```{r}
train_dmy <- dummyVars("~.", data=train, fullRank=T) #generate n-1 columns
train_transform <- data.frame(predict(train_dmy, newdata = train))


```


```{r}
library(GGally)
ggpairs(train, aes(colour = Survived, alpha = 0.4))
```



```{r missingvalue}
#how to impute blank for both training and testing?
#train_df%>%summarise_each(funs(sum(is.na(.))))
train[is.na(train$Age), "Age"] <- median(train$Age, na.rm=T)
test[is.na(test$Age), "Age"] <- median(test$Age, na.rm=T)
test[is.na(test$Fare), "Fare"] <- median(test$Fare, na.rm=T)
train[is.na(train$Embarked), "Embarked"] <- "S"

```
```{r train_test_split}
trainIndex <- createDataPartition(train$Survived, p = .7, list = FALSE)
train_df <- train[trainIndex,]
validate_df <- train[-trainIndex,]
```

```{r results = 'hide'}
set.seed(111)
control <- trainControl(method="cv", number=10, verboseIter = TRUE)

model_tree <- train(Survived ~.,
                  method="rpart",
                  train_df,
                  metric = "Accuracy",
                  trControl = control,
                  preProcess = c("center", "scale"))

model_rf <- train(Survived ~.,  
                  method="ranger",
                  train_df, 
                  metric = "roc",
                  tuneLength = 10,
                  trControl = control,
                  preProcess = c("center", "scale"))

model_knn <- train(Survived ~.,  
                  method="knn",
                  train_df, 
                  metric = "roc",
                  trControl = control,
                  preProcess = c("center", "scale"))

model_svclinear <- train(Survived ~.,  
                  method="svmLinear",
                  train_df, 
                  metric = "roc",
                  trControl = control,
                  preProcess = c("center", "scale"))

model_svcradial <- train(Survived ~.,  
                  method="svmRadial",
                  train_df, 
                  metric = "roc",
                  trControl = control,
                  preProcess = c("center", "scale"))

model_lda <- train(Survived ~.,  
                  method="lda",
                  train_df, 
                  metric = "roc",
                  tuneLength = 10,
                  trControl = control,
                  preProcess = c("center", "scale"))

model_nb <- train(Survived ~.,  
                  method="naive_bayes",
                  train_df, 
                  metric = "roc",
                  tuneLength = 10,
                  trControl = control,
                  preProcess = c("center", "scale"))
```



```{r}
# model_xgboost <- train(Survived ~.,  
#                   method="xgboost",
#                   train_df, 
#                   metric = "roc",
#                   trControl = control,
#                   preProcess = c("center", "scale"))
#pred <- predict(my_model, validate_df)
#confusionMatrix(data=pred, validate_df$Class)



# xgb <- xgboost(data = as.matrix(train_df), 
#  label = train_df$Survived, 
#  eta = 0.1,
#  max_depth = 15, 
#  nround=2, 
#  objective = "binary:logistic")
# )
#Error in xgb.DMatrix(data, label = label, missing = missing) : [22:39:14] amalgamation/../dmlc-core/src/io/local_filesys.cc:66: LocalFileSystem.GetPathInfo 0 Error:No such file or directory
```

```{r}
#neuralnet from caret only deal with regression, whereas nnet deal with classification

#convert factor to numeric
train$Survived=as.numeric(as.character(train$Survived))
train$Pclass=as.numeric(as.character(train$Pclass))

#fit nn model
# model_nn <- neuralnet(Survived~Pclass+Age+SibSp+Parch+Fare, 
#                       train, hidden=3, linear.output=F)
#   
# 
# nn_predict <- neuralnet::compute(model_nn, 
#                       test[c("Pclass", "Age", "SibSp", "Parch", "Fare")])$net.result[,1]


# model_nnet <- train(Survived ~.,  
#                   method="nnet",
#                   train_df, 
#                   linout=FALSE, trace = FALSE,
#                   preProcess = c("center", "scale"))
#   
# nnet_predict <- predict(model_nnet, validate_df)

#use one-hot encoding
model_nnet <- train(as.factor(Survived) ~.,  
                  method="nnet",
                  train_transform, 
                  linout=FALSE, trace = FALSE,
                  preProcess = c("center", "scale"))
  
nnet_predict <- predict(model_nnet, test_transform)

confusionmx <- table(Real.Class = validate_df$Survived, predicted=nnet_predict)
error=1-sum(diag(confusionmx))*1.0/sum(confusionmx)
error

test$Pclass = as.factor(test$Pclass)
test$Sex = as.factor(test$Sex)



```
```{r}
test_partial = test[setdiff(colnames(validate_df),"Survived")]
test_partial
test_dmy <- dummyVars("~.", data=test_partial, fullRank=T) #generate n-1
test_transform <- data.frame(predict(test_dmy, newdata = test_partial))

nnet_outcome<- predict(model_nnet, test_partial)
length(nnet_outcome)
```


```{r}
model_list <- list(rf = model_rf, 
                   knn = model_knn,
                   svc_linear = model_svclinear,
                   svc_raidal = model_svcradial, 
                   lda = model_lda,
                   nb = model_nb)
resamples = resamples(model_list)
summary(resamples)
dotplot(resamples)
```
results show random foreast and SVM Radial worked the best among the used algorithms.

#autoML
```{r auto}
train_df = as.h2o(train_df)
validate_df = as.h2o(validate_df) 

x = c("Pclass","Sex","Age","SibSp","Parch","Fare")
y="Survived"

aml <- h2o.automl(x = x, 
                  y = y,
                  training_frame = train_df,
                  leaderboard_frame = validate_df,
                  max_runtime_secs = 30)

# View the AutoML Leaderboard
lb <- aml@leaderboard
lb

```
```{r autopredict}
test <- as.h2o(test)
h2o_pred <- h2o.predict(aml, test)
```
Somehow autoML prediction didn't beat RF


#xgboost
```{r}
model_xgb <- xgb.cv(data = as.matrix(train_transform[,2:9]), 
            label = train_transform$Survived,
            nrounds = 100,
            nfold = 5,
            objective = "binary:logistic",
            eta = 0.3,
            max_depth = 6,
            early_stopping_rounds = 10,
            verbose = 0    # silent
)

library(caret)
test$pred <- xgboost::predict(model_xgb, as.matrix(test_partial))
#Error: 'predict' is not an exported object from 'namespace:xgboost'
```


##Predict class


```{r}
#submission <- predict(model_rf, test)
test <- read_csv("test.csv")
submission = data.frame(test$PassengerId, nnet_outcome)
colnames(submission) = c("PassengerId", "Survived")

write.csv(submission, "titanic_submission6", row.names = FALSE)
```


```{r session}
sessionInfo()
#v5 rf
#v6 nnet
```

